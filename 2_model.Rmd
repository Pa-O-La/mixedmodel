---
title: "2 Model"
author: "Riccardo Bertoglio, Paola Mussida"
date: 07/07/2020
output:
  ioslides_presentation: default
  slidy_presentation: default
  beamer_presentation: default
---

<style type="text/css">

<!-- body{ /* Normal  */
      font-size: 18px;
  }
td {  /* Table  */
  font-size: 6px;
} 
h1.title {
  font-size: 36px;
}
h1 { /* Header 1 */
  font-size: 26px;
} -->
h2 { /* Header 2 */
  font-size: 36px;
}
<!-- h3 { /* Header 3 */
  font-size: 16px;
} 
code.r{ /* Code block */
    font-size: 16px;
} -->
pre { /* Code block - determines code spacing between lines */
    font-size: 16px;
    margin-top: 0;
    max-width: 95%;
    border: 1px solid #ccc;
    white-space: pre-wrap;
    max-height: 500px;
    overflow-y: auto;
}
ul,ol {font-size: 16px;}

<!-- scroll-150 { -->
<!--   max-height: 150px; -->
<!--   overflow-y: auto; -->
<!--   background-color: inherit; -->
<!-- } -->
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
```

## Some initial operations

```{r, include = FALSE}
mydirdo <- paste0(getwd(),"/data/dataout/")
dataset <- read.csv(paste0(mydirdo,'dataset.csv'))

# Upload libraries
library(tidyverse)
library(caret)
library(lme4)
library(party)
library(PRROC)

# Dataset description to set correct type
str(dataset)
dataset$CARR_AN_ID <- as.character(dataset$CARR_AN_ID)
dataset$CARR_INGR_AA <- as.factor(dataset$CARR_INGR_AA)
dataset$PERS_NAS_YYYY <- as.factor(dataset$PERS_NAS_YYYY)
dataset$PERS_CITT_STT_ID <- as.factor(dataset$PERS_CITT_STT_ID)
#set Italy as reference level
dataset$PERS_CITT_STT_ID <- relevel(dataset$PERS_CITT_STT_ID, 1)
```
- The relevel function specifies which level to use as reference
<!-- It is useful for specifying a reference for categorical values in linear regression models -->
```{r, echo = TRUE}
#set Milan as reference level
dataset$HOM_GEO_PRV_DN <- relevel(dataset$HOM_GEO_PRV_DN, 'Milano')
```
```{r, include = FALSE}
#set Scientific Previous Studies as reference level
dataset$TIT_MED_TP_CD_ELAB <- as.factor(dataset$TIT_MED_TP_CD_ELAB)
dataset$TIT_MED_TP_CD_ELAB <- relevel(dataset$TIT_MED_TP_CD_ELAB, 'S ')
#set MI as reference level
dataset$TIT_MED_GEO_PRV_CD <- relevel(dataset$TIT_MED_GEO_PRV_CD, 'MI')
dataset$CHANGEDEGREE <- as.factor(dataset$CHANGEDEGREE)
str(dataset)
```
- Scaling of numerical features
```{r, echo = TRUE}
dataset[, c("CARR_ING_ETA","TIT_CONS_VOTO","CFU_PASSATI","MEDIA_PESATA","FAILED_CFU","STUD_AMM_VOTO_REPLACED_MEDIAN")] <- scale(dataset[, c("CARR_ING_ETA","TIT_CONS_VOTO","CFU_PASSATI","MEDIA_PESATA","FAILED_CFU","STUD_AMM_VOTO_REPLACED_MEDIAN")])
```
- We remove the careers with CARR_INGR_AA == 2019, 2018 and 2017
```{r, echo = TRUE}
dataset_until_2016 <- dataset[dataset$CARR_INGR_AA!=2019 & dataset$CARR_INGR_AA!=2018 & dataset$CARR_INGR_AA!=2017, ]
```
```{r, include = FALSE}
# we drop CARR_AN_ID because it's the key value
drops <- c("CARR_AN_ID")
dataset_until_2016 <- dataset_until_2016[ , !(names(dataset_until_2016) %in% drops)]
# Update of the levels
dataset_until_2016 <- droplevels(dataset_until_2016)
```
- If STATUS==DE ("Dropout Early") put TRUE, otherwise FALSE
```{r, echo = TRUE}
dataset_until_2016$STATUS <- ifelse(dataset_until_2016$STATUS=='DE',1,0)
```
```{r, include = FALSE}
dataset_until_2016$STATUS <- as.factor(dataset_until_2016$STATUS)
# we move the STATUS feature as last column
dataset_until_2016 <- dataset_until_2016[,c(1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,7)]
```

## TAX levels
```{r, include=FALSE}
# we reduce tax levels
tax.table1 <- table(dataset_until_2016$TAX)
dataset_until_2016.taxred <- dataset_until_2016
dataset_until_2016.taxred$TAX = as.character(dataset_until_2016.taxred$TAX)
for(i in 1:dim(dataset_until_2016.taxred)[1]){
  dataset_until_2016.taxred$TAX[i]=
    switch(as.character(dataset_until_2016.taxred$TAX[i]),
             'LS' = 'BASSA',
             '01' = 'BASSA',
             '02' = 'BASSA',
             '03' = 'BASSA',
             '04' = 'MEDIA',
             '05' = 'MEDIA',
             '06' = 'ALTA',
             '07' = 'ALTA',
             '08' = 'ALTA',
             'CP' = 'CP',
             dataset_until_2016.taxred$TAX[i] #default lascio invariato
    )
}
dataset_until_2016.taxred$TAX = as.factor(dataset_until_2016.taxred$TAX)
#set BASSA as reference level
dataset_until_2016.taxred$TAX <- relevel(dataset_until_2016.taxred$TAX, 'BASSA')
```
```{r, figures-side, fig.show="hold", out.width="50%"}
# pie chart
pie(tax.table1, radius=1)
tax.table2 <- table(dataset_until_2016.taxred$TAX)
# pie chart
pie(tax.table2, radius=1)
# proportions in percentage
round(prop.table(tax.table1), digits=2)
# proportions in percentage
round(prop.table(tax.table2), digits=2)
```

## TIT_MED_TP_CD_ELAB levels
```{r, include=FALSE}
tit_med.table1 <- table(dataset_until_2016.taxred$TIT_MED_TP_CD_ELAB)
dataset_until_2016.titTaxRed <- dataset_until_2016.taxred
dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB = as.vector(dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB)
for( i in 1:length(dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB )) {
  if( !is.element(dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB [i], c("S ", "T", "-E"))){
    dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB [i] = "O"
  }
}
dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB <- as.factor(dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB)
dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB <- relevel(dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB, 'S ')
```

```{r, fig.show="hold", out.width="50%"}
# pie chart
pie(tit_med.table1, radius=1)
tit_med.table2 <- table(dataset_until_2016.titTaxRed$TIT_MED_TP_CD_ELAB)
# pie chart
pie(tit_med.table2, radius=1)
# proportions in percentage
round(prop.table(tit_med.table1), digits=4)
# proportions in percentage
round(prop.table(tit_med.table2), digits=2)
```

## Correlation matrix
```{r, include=FALSE}
dataset_until_2016 <- rename (dataset_until_2016, STUD_AMM_VOTO = STUD_AMM_VOTO_REPLACED_MEDIAN)

set.seed(7)
# calculate correlation matrix for numerical attributes
correlationMatrix <- cor(dataset_until_2016[,c("CARR_ING_ETA","TIT_CONS_VOTO" ,"CV_NOR_YY", "ENG_NOR_YY", "FIS_NOR_YY", "MAT_NOR_YY","CFU_PASSATI","MEDIA_PESATA","FAILED_CFU","STUD_AMM_VOTO")])
# summarize the correlation matrix
print(correlationMatrix)
# CFU_PASSATI and MEDIA_PESATA are highly correlated (0.79)
# MAT_NOR_YY and STUD_AMM_VOTO_REPLACED_MEDIAN are highly correlated (0.88)
library(corrplot)
```
- CFU_PASSATI and MEDIA_PESATA are highly correlated (0.79)
- MAT_NOR_YY and STUD_AMM_VOTO are highly correlated (0.88)
```{r}
corrplot(correlationMatrix, tl.cex=0.7, tl.srt=26)
```


## Random forest
```{r, echo=FALSE}
cf1 <- cforest(STATUS~. , data=dataset_until_2016.titTaxRed[,c(1:22)], control=cforest_unbiased(mtry=2,ntree=50))
```
```{r}
variable_importance <- varimp(cf1)
sort(variable_importance)
```

## Data splitting
```{r, echo=TRUE}
# Split the data into temp and test set
set.seed(123)
training.samples <- createDataPartition(dataset_until_2016.titTaxRed$STATUS, p = 0.8, list = FALSE)
temp.data <- dataset_until_2016.titTaxRed[training.samples, ]
test.data <- dataset_until_2016.titTaxRed[-training.samples, ]

# Split the data into training and validation set
training.samples <- createDataPartition(temp.data$STATUS, p = 0.8, list = FALSE)
train.data <- temp.data[training.samples, ]
validation.data <- temp.data[-training.samples, ]
```
## Models 0 and 1
```{r, echo=TRUE}
# Model 0: simple linear regression as comparison
mod0 <- glm(STATUS~ MEDIA_PESATA + CFU_PASSATI + FAILED_CFU + CHANGEDEGREE + TAX + TIT_CONS_VOTO + STUD_AMM_VOTO_REPLACED_MEDIAN + CARR_ING_ETA, family=binomial, data=train.data)


# Model 1: simple linear regression as comparison
# with TIT_MED_TP_CD_ELAB
mod1 <- glm(STATUS~ MEDIA_PESATA + CFU_PASSATI + FAILED_CFU + CHANGEDEGREE + TAX + TIT_CONS_VOTO + STUD_AMM_VOTO_REPLACED_MEDIAN + CARR_ING_ETA + TIT_MED_TP_CD_ELAB, family=binomial, data=train.data)
```

## Models 2 and 3
```{r, echo=TRUE}
# Model 2: COURSE as random effect
mod2 <- glmer(STATUS~(1|COURSE) + MEDIA_PESATA + CFU_PASSATI + FAILED_CFU + CHANGEDEGREE + TAX + TIT_CONS_VOTO + STUD_AMM_VOTO_REPLACED_MEDIAN + CARR_ING_ETA + TIT_MED_TP_CD_ELAB, family=binomial, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data=train.data)


# Model 3: COURSE and HOM_GEO_PRV_DN as random effects
mod3 <- glmer(STATUS~(1|COURSE) + (1|HOM_GEO_PRV_DN) + MEDIA_PESATA + CFU_PASSATI + FAILED_CFU + CHANGEDEGREE + TAX + TIT_CONS_VOTO + STUD_AMM_VOTO_REPLACED_MEDIAN + CARR_ING_ETA + TIT_MED_TP_CD_ELAB, family=binomial, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)), data=train.data)
```

## Akaike’s Information Criterion (AIC)
<!-- Model Selection Using Akaike’s Information Criterion (AIC). The simplest models with the lowest AIC values are considered the best-fitting models, with the important caveat that models within ΔAIC of 2 are considered to have equivalent fit -->
```{r, echo=TRUE}
AIC(mod0, mod1, mod2, mod3)
```
## Summary mod3
```{r, echo=FALSE}
summary(mod3)
```

## Prediction on validation and ROC curve
```{r}
predictions <- predict(mod3, validation.data, re.form=NULL,type="response", allow.new.levels=T)
actual_true_predictions <- predictions[validation.data$STATUS == 1]
actual_false_predictions <- predictions[validation.data$STATUS == 0]
 
roc <- roc.curve(scores.class0 = actual_true_predictions, scores.class1 = actual_false_predictions, curve = T)
plot(roc)
```

## Prediction on test and confusion matrix
```{r}
predictions <- predict(mod3, test.data, re.form=NULL,type="response", allow.new.levels=T)
factorized_predictions <- ifelse(predictions>=0.4,1,0)
factorized_predictions <- as.factor(factorized_predictions)
confusionMatrix(factorized_predictions, test.data$STATUS, positive = '1')
```